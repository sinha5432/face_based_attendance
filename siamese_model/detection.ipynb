{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preparing dataset to compare in prediction\n",
    "#Results may vary with these images as these will be used to compare faces\n",
    "\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "dir_read = r'/content/drive/MyDrive/face_detection_files/siamese_model/prediction_data/'\n",
    "\n",
    "for i, filename in enumerate(os.listdir(dir_read)):\n",
    "\n",
    "    frame = cv2.imread(dir_read + str(filename))\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    frame = cv2.resize(frame, (100, 100), interpolation = cv2.INTER_CUBIC)\n",
    "    cv2.imwrite(dir_read + 'new' + str(i) + '.jpg', frame)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "X = []\n",
    "\n",
    "dir_read = r'/content/drive/MyDrive/face_detection_files/siamese_model/prediction_data/'\n",
    "\n",
    "for i, filename in enumerate(os.listdir(dir_read)):\n",
    "  img = cv2.imread(dir_read + filename, cv2.IMREAD_GRAYSCALE)\n",
    "  X.append(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "save_path = r'prediction_data/'\n",
    "\n",
    "\n",
    "pickle.dump(x, open(save_path + \"x_pred.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pickle import load\n",
    "\n",
    "x_path = r'prediction_data/x_pred.pkl'\n",
    "\n",
    "with open(x_path, 'rb') as f:\n",
    "  x_val = load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 696,
     "status": "ok",
     "timestamp": 1625655033538,
     "user": {
      "displayName": "Manasvi Sinha",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggg6B7Dol6gHNz3V67BDIVoqO7HHq9s_uHG68ppFQ=s64",
      "userId": "09024498764210840462"
     },
     "user_tz": -330
    },
    "id": "wkgD7DFjBkYh"
   },
   "outputs": [],
   "source": [
    "# Provided two tensors t1 and t2\n",
    "# Euclidean distance = sqrt(sum(square(t1-t2)))\n",
    "def euclidean_distance(vects):\n",
    "    \"\"\"Find the Euclidean distance between two vectors.\n",
    "\n",
    "    Arguments:\n",
    "        vects: List containing two tensors of same length.\n",
    "\n",
    "    Returns:\n",
    "        Tensor containing euclidean distance\n",
    "        (as floating point value) between vectors.\n",
    "    \"\"\"\n",
    "\n",
    "    x, y = vects\n",
    "    sum_square = tf.math.reduce_sum(tf.math.square(x - y), axis=1, keepdims=True)\n",
    "    return tf.math.sqrt(tf.math.maximum(sum_square, tf.keras.backend.epsilon()))\n",
    "\n",
    "\n",
    "input = layers.Input((100, 100, 1))\n",
    "x = tf.keras.layers.BatchNormalization()(input)\n",
    "x = layers.Conv2D(8, (10, 10), activation=\"tanh\")(x)\n",
    "x = layers.AveragePooling2D(pool_size=(5, 5))(x)\n",
    "x = layers.Conv2D(64, (10, 10), activation=\"tanh\")(x)\n",
    "x = layers.AveragePooling2D(pool_size=(5, 5))(x)\n",
    "x = layers.Conv2D(128, (10, 10), activation=\"tanh\", padding=\"same\")(x)\n",
    "x = layers.AveragePooling2D(pool_size=(2, 2), padding=\"same\")(x)\n",
    "x = layers.Flatten()(x)\n",
    "\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = layers.Dense(20, activation=\"tanh\")(x)\n",
    "embedding_network = keras.Model(input, x)\n",
    "\n",
    "\n",
    "input_1 = layers.Input((100, 100, 1))\n",
    "input_2 = layers.Input((100, 100, 1))\n",
    "\n",
    "# As mentioned above, Siamese Network share weights between\n",
    "# tower networks (sister networks). To allow this, we will use\n",
    "# same embedding network for both tower networks.\n",
    "tower_1 = embedding_network(input_1)\n",
    "tower_2 = embedding_network(input_2)\n",
    "\n",
    "merge_layer = layers.Lambda(euclidean_distance)([tower_1, tower_2])\n",
    "normal_layer = tf.keras.layers.BatchNormalization()(merge_layer)\n",
    "output_layer = layers.Dense(1, activation=\"sigmoid\")(normal_layer)\n",
    "siamese = keras.Model(inputs=[input_1, input_2], outputs=output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 415,
     "status": "ok",
     "timestamp": 1625655295770,
     "user": {
      "displayName": "Manasvi Sinha",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggg6B7Dol6gHNz3V67BDIVoqO7HHq9s_uHG68ppFQ=s64",
      "userId": "09024498764210840462"
     },
     "user_tz": -330
    },
    "id": "VV87zBnHDGqg"
   },
   "outputs": [],
   "source": [
    "def loss(margin=1):\n",
    "    \"\"\"Provides 'constrastive_loss' an enclosing scope with variable 'margin'.\n",
    "\n",
    "  Arguments:\n",
    "      margin: Integer, defines the baseline for distance for which pairs\n",
    "              should be classified as dissimilar. - (default is 1).\n",
    "\n",
    "  Returns:\n",
    "      'constrastive_loss' function with data ('margin') attached.\n",
    "  \"\"\"\n",
    "\n",
    "    # Contrastive loss = mean( (1-true_value) * square(prediction) +\n",
    "    #                         true_value * square( max(margin-prediction, 0) ))\n",
    "    def contrastive_loss(y_true, y_pred):\n",
    "        \"\"\"Calculates the constrastive loss.\n",
    "\n",
    "      Arguments:\n",
    "          y_true: List of labels, each label is of type float32.\n",
    "          y_pred: List of predictions of same length as of y_true,\n",
    "                  each label is of type float32.\n",
    "\n",
    "      Returns:\n",
    "          A tensor containing constrastive loss as floating point value.\n",
    "      \"\"\"\n",
    "\n",
    "        square_pred = tf.math.square(y_pred)\n",
    "        margin_square = tf.math.square(tf.math.maximum(margin - (y_pred), 0))\n",
    "        return tf.math.reduce_mean(\n",
    "            (1 - y_true) * square_pred + (y_true) * margin_square\n",
    "        )\n",
    "\n",
    "    return contrastive_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "batch_size = 16\n",
    "margin = 1  # Margin for constrastive loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6691,
     "status": "ok",
     "timestamp": 1625655393909,
     "user": {
      "displayName": "Manasvi Sinha",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggg6B7Dol6gHNz3V67BDIVoqO7HHq9s_uHG68ppFQ=s64",
      "userId": "09024498764210840462"
     },
     "user_tz": -330
    },
    "id": "f0ts702qnJZS",
    "outputId": "d0e8c06a-9c09-42b2-d074-970bdb98a53f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 100, 100, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 100, 100, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "functional_1 (Functional)       (None, 20)           874496      input_2[0][0]                    \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 1)            0           functional_1[0][0]               \n",
      "                                                                 functional_1[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 1)            4           lambda[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            2           batch_normalization_2[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 874,502\n",
      "Trainable params: 874,242\n",
      "Non-trainable params: 260\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "siamese.compile(loss=loss(margin=margin), optimizer=\"RMSprop\", metrics=[\"accuracy\"])\n",
    "siamese.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese.load_weights('siamese_model_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 408,
     "status": "ok",
     "timestamp": 1625655399015,
     "user": {
      "displayName": "Manasvi Sinha",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggg6B7Dol6gHNz3V67BDIVoqO7HHq9s_uHG68ppFQ=s64",
      "userId": "09024498764210840462"
     },
     "user_tz": -330
    },
    "id": "_o315NHxnDL-"
   },
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "\n",
    "mpFaceDetection = mp.solutions.face_detection\n",
    "faceDetection = mpFaceDetection.FaceDetection(0.45)\n",
    "\n",
    "def face_extractor(frame):\n",
    "    \n",
    "    imgRGB = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = faceDetection.process(imgRGB)\n",
    "    \n",
    "    \n",
    "    if(results.detections):\n",
    "        for id, detection in enumerate(results.detections):\n",
    "            \n",
    "            bboxC = detection.location_data.relative_bounding_box\n",
    "            img_h, img_w, img_c = frame.shape\n",
    "            \n",
    "            xmin = int(bboxC.xmin * img_w)\n",
    "            ymin = int(bboxC.ymin * img_h)\n",
    "            w = int(bboxC.width * img_w)\n",
    "            h = int(bboxC.height * img_h)\n",
    "            \n",
    "            \n",
    "            bbox = (int(bboxC.xmin * img_w), int(bboxC.ymin * img_h), int(bboxC.width * img_w), int(bboxC.height * img_h))\n",
    "\n",
    "            new_frame = frame[ymin:ymin+h, xmin:xmin+w]\n",
    "            \n",
    "    \n",
    "            return new_frame, bbox\n",
    "    else:\n",
    "        \n",
    "        return np.array([]), []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_val[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 371
    },
    "executionInfo": {
     "elapsed": 420,
     "status": "error",
     "timestamp": 1625655535046,
     "user": {
      "displayName": "Manasvi Sinha",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggg6B7Dol6gHNz3V67BDIVoqO7HHq9s_uHG68ppFQ=s64",
      "userId": "09024498764210840462"
     },
     "user_tz": -330
    },
    "id": "XZfYUiu0nTiR",
    "outputId": "abc7283a-f4b9-44df-a6af-719a1fac276c",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import cv2\n",
    "\n",
    "\n",
    "video_capture = cv2.VideoCapture(0)\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "\n",
    "pTime = time.time();\n",
    "\n",
    "while True:\n",
    "    _, frame = video_capture.read()\n",
    "    \n",
    "    face, bbox=face_extractor(frame)\n",
    "    \n",
    "    if(face.size):\n",
    "        face = cv2.resize(face, (100, 100)) #Resizing into 100x100 because we trained the model with this image size.\n",
    "        face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        #Our keras model used a 4D tensor, (images x height x width x channel)\n",
    "        #So changing dimension 128x128x3 into 1x128x128x3 \n",
    "        img_array = np.expand_dims(face, axis=0)\n",
    "        \n",
    "        pred = []\n",
    "        \n",
    "        for i in range(4):\n",
    "            x = np.expand_dims(x_val[i], axis=0)\n",
    "            temp = siamese.predict([img_array, x])\n",
    "            pred.append(temp)\n",
    "\n",
    "        pred = np.asarray(pred)\n",
    "        prediction = np.argmax(pred)\n",
    "#         print(prediction, end = '\\r')\n",
    "\n",
    "        if(prediction == 0):\n",
    "            text = 'Bill Gates'\n",
    "        elif(prediction == 1):\n",
    "            text = 'Barack Obama'\n",
    "        elif(prediction == 2):\n",
    "            text = 'Donald Trump'\n",
    "        elif(prediction == 3):\n",
    "            text = 'Queen Elizabeth II'\n",
    "\n",
    "        cv2.rectangle(frame, bbox, (57, 255, 20), 2)\n",
    "        cv2.putText(frame, text, (bbox[0],bbox[1]-20), font, 0.8, (57, 255, 20), 2)\n",
    "        \n",
    "    else:\n",
    "        cv2.putText(frame, 'Face not found', (10, 50), font, 0.8, (57, 255, 20), 2)\n",
    "    \n",
    "    cTime = time.time()\n",
    "    fps = int(1/(cTime - pTime))\n",
    "    pTime = cTime\n",
    "\n",
    "    cv2.putText(frame, 'FPS: ' + str(fps), (10, 20), font, 0.8, (57, 255, 20), 2)\n",
    "    \n",
    "    cv2.imshow('video', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "        \n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FnaF0syGFHNW"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMlHOHPDIpceCresfwRibqV",
   "collapsed_sections": [],
   "name": "detection.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
